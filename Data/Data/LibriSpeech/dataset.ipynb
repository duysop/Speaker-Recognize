{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENT MFCC FOR SOUND PROCESSING USING FAST FOURIER TRANSFORM\n",
    "Mel Frequency Cepstral Coefficents (MFCCs) are a feature widely used in automatic speech and speaker recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m num\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(num)\n\u001b[0;32m     19\u001b[0m p1[p1[\u001b[39m'\u001b[39m\u001b[39mID   \u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mnum]\u001b[39m.\u001b[39mindex\n\u001b[1;32m---> 20\u001b[0m A\u001b[39m=\u001b[39mMFCC(TRAIN_PATH,\u001b[39mlist\u001b[39;49m)\n\u001b[0;32m     21\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(A\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m     23\u001b[0m data\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Documents\\GitHub\\Sound-processing\\Data\\LibriSpeech\\MFCC.py:34\u001b[0m, in \u001b[0;36mMFCC\u001b[1;34m(TRAIN_PATH, file)\u001b[0m\n\u001b[0;32m     31\u001b[0m audio_fft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((\u001b[39mint\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m FFT_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m), audio_winT\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mcomplex64, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mF\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(audio_fft\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m---> 34\u001b[0m     audio_fft[:, n] \u001b[39m=\u001b[39m fft\u001b[39m.\u001b[39;49mfft(audio_winT[:, n], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[:audio_fft\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]]\n\u001b[0;32m     36\u001b[0m audio_fft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(audio_fft)\n\u001b[0;32m     37\u001b[0m audio_power \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msquare(np\u001b[39m.\u001b[39mabs(audio_fft))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\abcd\\lib\\site-packages\\scipy\\fftpack\\_basic.py:88\u001b[0m, in \u001b[0;36mfft\u001b[1;34m(x, n, axis, overwrite_x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfft\u001b[39m(x, n\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, overwrite_x\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    Return discrete Fourier transform of real or complex sequence.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m _pocketfft\u001b[39m.\u001b[39;49mfft(x, n, axis, \u001b[39mNone\u001b[39;49;00m, overwrite_x)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\abcd\\lib\\site-packages\\scipy\\fft\\_pocketfft\\basic.py:31\u001b[0m, in \u001b[0;36mc2c\u001b[1;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minvalid number of data points (\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m) specified\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m                      \u001b[39m.\u001b[39mformat(tmp\u001b[39m.\u001b[39mshape[axis]))\n\u001b[0;32m     29\u001b[0m out \u001b[39m=\u001b[39m (tmp \u001b[39mif\u001b[39;00m overwrite_x \u001b[39mand\u001b[39;00m tmp\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m---> 31\u001b[0m \u001b[39mreturn\u001b[39;00m pfft\u001b[39m.\u001b[39;49mc2c(tmp, (axis,), forward, norm, out, workers)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from MFCC import *\n",
    "TRAIN_PATH='train-clean-wav/'\n",
    "p1=pd.read_csv('newdata.csv',sep=';')\n",
    "p1['ID   ']=p1['ID   '].astype(int)\n",
    "listdata=[]\n",
    "files=os.listdir(TRAIN_PATH)\n",
    "list1=files[0:int(len(files)/10)]\n",
    "for list in list1:\n",
    "    num=\"\"\n",
    "    for char in list:\n",
    "        if char==\"-\" :\n",
    "            break\n",
    "        num+=char\n",
    "    num=int(num)\n",
    "    p1[p1['ID   ']==num].index\n",
    "    A=MFCC(TRAIN_PATH,list)\n",
    "    indices = np.arange(A.shape[1])\n",
    "\n",
    "    data=dict()\n",
    "    data['cepstrum']=np.transpose(A[:,np.random.choice(indices, size=50, replace=False)])\n",
    "    data['speaker']=p1.iloc[p1[p1['ID   ']==num].index][' NAME'].values[0]\n",
    "    data['sex']=p1.iloc[p1[p1['ID   ']==num].index]['SEX'].values[0]\n",
    "    listdata.append(data)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m listdata\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmy_dict.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     pickle\u001b[39m.\u001b[39mdump(listdata, f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listdata' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "listdata\n",
    "with open('my_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(listdata, f)\n",
    "with open('my_dictRNN.pkl', 'rb') as f:\n",
    "    my_dict = pickle.load(f)\n",
    "my_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
